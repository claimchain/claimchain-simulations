{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulations.scenarios import *\n",
    "from simulations.agent import *\n",
    "from simulations.utils import Context\n",
    "from scripts.parse_enron import Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"white\")\n",
    "# sns.set_palette(\"deep\")\n",
    "sns.set_palette(sns.cubehelix_palette(n_colors=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_logs_folder = '../Enron/parsing/'\n",
    "social_graph = pickle.load(open(parsed_logs_folder + \"social.pkl\", \"rb\"))\n",
    "\n",
    "enron_log = pickle.load(open(parsed_logs_folder + \"replay_log.pkl\", \"rb\"))\n",
    "LOG_SIZE = len(enron_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_private_setting = AgentSettings(key_update_every_nb_sent_emails=None, key_update_every_nb_days=5)\n",
    "dynamic_public_setting = AgentSettings(key_update_every_nb_sent_emails=None, key_update_every_nb_days=5,\n",
    "                                       introduction_policy=public_contacts_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_encryption_status_plots(scenario_name, reports, breakpoints=None, mask_fn=None):\n",
    "    if breakpoints is None:\n",
    "        breakpoints = range(len(reports) + 1)\n",
    "        \n",
    "    fig, axes = plt.subplots(nrows=5, ncols=2)\n",
    "    fig.set_figwidth(15)\n",
    "    fig.set_figheight(30)\n",
    "    axes = list(itertools.chain.from_iterable(axes))\n",
    "\n",
    "    for i, (offset, report, ax) in enumerate(zip(breakpoints[:-1], reports, axes)):\n",
    "        if mask_fn is not None:\n",
    "            mask = mask_fn(report)\n",
    "        else:\n",
    "            mask = None\n",
    "        visualize_encryption_status_history('%s (log chunk @%d)' % (scenario_name, offset),\n",
    "                                            report.encryption_status_data,\n",
    "                                            report.link_status_data,\n",
    "                                            mask=mask,\n",
    "                                            ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_enc_stats_in_batches(enc_status_data, link_status_data, mask=None, batch_size=1000):\n",
    "    log_size = enc_status_data.index[-1] + 1\n",
    "    batch_stats_data = pd.DataFrame(columns=['Stale key', 'Encrypted',\n",
    "                                             'Plaintext (initial contact)', 'Plaintext (follow-up)'])\n",
    "    for i in range(0, log_size, batch_size):\n",
    "        enc_status_batch = enc_status_data.loc[i:i+batch_size].dropna()\n",
    "        link_status_batch = link_status_data.loc[i:i+batch_size].dropna()\n",
    "        if mask is not None:\n",
    "            mask_batch = mask.loc[i:i+batch_size]\n",
    "            enc_status_batch = enc_status_batch[mask_batch]\n",
    "            link_status_batch = link_status_batch[mask_batch]\n",
    "\n",
    "        if len(enc_status_batch) == 0:\n",
    "            continue\n",
    "\n",
    "        #joined_data_batch = pd.concat({'l': link_status_batch, 'e': enc_status_batch}, axis=1).dropna()\n",
    "        ## This was done to drop rows where enc. status is None.\n",
    "        #enc_status_batch = joined_data_batch['e'][0]\n",
    "        #link_status_batch = joined_data_batch['l']\n",
    "        \n",
    "        encrypted_prop = np.mean(enc_status_batch == EncStatus.encrypted) * 100\n",
    "        stale_prop = np.mean(enc_status_batch == EncStatus.stale) * 100\n",
    "        \n",
    "        # Proportion of initial contacts\n",
    "        plain_status_batch = link_status_batch[enc_status_batch == EncStatus.plaintext]\n",
    "        greeting_mask = plain_status_batch['greeting'] > 0\n",
    "        followup_mask = plain_status_batch['followup'] > 0\n",
    "        greeting_prop = np.sum(greeting_mask & ~followup_mask) / len(link_status_batch) * 100\n",
    "        followup_prop = np.sum(followup_mask) / len(link_status_batch) * 100\n",
    "        \n",
    "        batch_stats_data.loc[i] = [stale_prop, encrypted_prop, greeting_prop, followup_prop]\n",
    "    return batch_stats_data\n",
    "\n",
    "def visualize_encryption_status_history(title, enc_status_data, link_status_data, mask=None,\n",
    "                                        batch_size=1000, legend_kwargs=None, ax=None,\n",
    "                                        show_title=False, show_legend=False):\n",
    "    if legend_kwargs is None:\n",
    "        legend_kwargs = {}\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    batch_stats_data = compute_enc_stats_in_batches(enc_status_data, link_status_data, mask, batch_size)\n",
    "    batch_stats_data.plot.area(ax=ax)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    legend = ax.legend(handles[::-1], labels[::-1], frameon=True, **legend_kwargs)\n",
    "    if not show_legend:\n",
    "        legend.remove()\n",
    "    if show_title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(\"Email sent\")\n",
    "    ax.set_ylabel(\"Email encryption status, %\")\n",
    "    ax.set_ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dynamic_public_setting.as_default():\n",
    "    context = Context(enron_log[0:1000], social_graph=social_graph)\n",
    "    public_report = simulate_claimchain(context)\n",
    "    \n",
    "with dynamic_private_setting.as_default():\n",
    "    context = Context(enron_log[0:1000], social_graph=social_graph)\n",
    "    private_report = simulate_claimchain(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=True)\n",
    "batch_size = 100\n",
    "\n",
    "visualize_encryption_status_history('Public ClaimChain',\n",
    "                                    public_report.encryption_status_data,\n",
    "                                    public_report.link_status_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    ax=axes[0][0])\n",
    "\n",
    "visualize_encryption_status_history('Private ClaimChain',\n",
    "                                    private_report.encryption_status_data,\n",
    "                                    private_report.link_status_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    ax=axes[0][1])\n",
    "\n",
    "visualize_encryption_status_history('Public ClaimChain (Userset only)',\n",
    "                                    public_report.encryption_status_data,\n",
    "                                    public_report.link_status_data,\n",
    "                                    public_report.participants_type_data == ParticipantsTypes.userset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    ax=axes[1][0])\n",
    "\n",
    "visualize_encryption_status_history('Private ClaimChain (Userset only)',\n",
    "                                    private_report.encryption_status_data,\n",
    "                                    private_report.link_status_data,\n",
    "                                    private_report.participants_type_data == ParticipantsTypes.userset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    ax=axes[1][1])\n",
    "\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate private ClaimChain at different starting points in the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_CHUNK_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "private_reports = []\n",
    "breakpoints = [int(i) for i in np.linspace(0, LOG_SIZE, 11)]\n",
    "\n",
    "## Compute new reports\n",
    "# for i in breakpoints[:-1]:\n",
    "#     context = Context(enron_log[i : i + LOG_CHUNK_SIZE], social_graph=social_graph)\n",
    "#     with dynamic_private_setting.as_default():\n",
    "#         private_reports.append(simulate_claimchain(context))\n",
    "#     with open('reports/private_claimchain_report-%d.pkl' % i, 'wb') as h:\n",
    "#         pickle.dump(private_reports[-1], h)\n",
    "\n",
    "# Load reports\n",
    "for i in breakpoints[:-1]:\n",
    "    with open('reports/private_claimchain_report-%d.pkl' % i, 'rb') as h:\n",
    "        report = pickle.load(h)\n",
    "        private_reports.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global encryption traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_encryption_status_plots('Private ClaimChain', private_reports, breakpoints=breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic within the userset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "make_encryption_status_plots('Private ClaimChain', private_reports, breakpoints=breakpoints,\n",
    "                             mask_fn=lambda report: report.participants_type_data == ParticipantsTypes.userset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average encryption proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_enc_status_data(report, mask=None, batch_size=1000):\n",
    "    cuts = [4000, 7000, 10000]\n",
    "\n",
    "    enc_stats_batches = compute_enc_stats_in_batches(\n",
    "        report.encryption_status_data, report.link_status_data, mask=mask)\n",
    "    \n",
    "    if mask is not None:\n",
    "        enc_status_data = report.encryption_status_data[mask]\n",
    "    else:\n",
    "        enc_status_data = report.encryption_status_data\n",
    "        \n",
    "    enc_avg_data = pd.DataFrame(columns=['Last batch average', 'Overall average'])\n",
    "    for cut in cuts:\n",
    "        # Average of immediate %\n",
    "        batch_avg = enc_stats_batches['Encrypted'].loc[cut-batch_size]\n",
    "\n",
    "        # Overall average\n",
    "        slice_stats = enc_status_data.loc[:cut].value_counts()\n",
    "        nb_encrypted = slice_stats.get(EncStatus.encrypted) or 0 \n",
    "        overall_avg = nb_encrypted / slice_stats.sum() * 100\n",
    "\n",
    "        enc_avg_data.loc[cut] = (batch_avg, overall_avg)\n",
    "\n",
    "    return enc_avg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "for i, (offset, report) in enumerate(zip(breakpoints, private_reports)):\n",
    "    display(HTML('<h4>@%d</h4>' % offset))\n",
    "    a = get_average_enc_status_data(report)\n",
    "    b = get_average_enc_status_data(report,\n",
    "        mask=report.participants_type_data==ParticipantsTypes.userset)\n",
    "    df = pd.concat({'global': a, 'userset': b}, axis=1)\n",
    "    summaries.append(df)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats over all chunks\n",
    "global_last_batch_df = pd.concat(\n",
    "    [s['global']['Last batch average'] for s in summaries], axis=1)\n",
    "userset_last_batch_df = pd.concat(\n",
    "    [s['userset']['Last batch average'] for s in summaries], axis=1)\n",
    "global_overall_df = pd.concat(\n",
    "    [s['global']['Overall average'] for s in summaries], axis=1)\n",
    "userset_overall_df = pd.concat(\n",
    "    [s['userset']['Overall average'] for s in summaries], axis=1)\n",
    "\n",
    "def compute_stats_over_chunks(data):\n",
    "    return pd.DataFrame({\n",
    "        'Avg': data.mean(axis=1), \n",
    "        'Std': data.std(axis=1),\n",
    "        'Std * 2.26': data.std(axis=1) * 2.26   # 95% t-val for df=9\n",
    "    })\n",
    "\n",
    "display(pd.concat({\n",
    "    'Last batch average (global)': compute_stats_over_chunks(global_last_batch_df),\n",
    "    'Last batch average (userset)': compute_stats_over_chunks(userset_last_batch_df),\n",
    "}, axis=1))\n",
    "\n",
    "display(pd.concat({\n",
    "    'Overall average (global)': compute_stats_over_chunks(global_overall_df),\n",
    "    'Overall average (userset)': compute_stats_over_chunks(userset_overall_df),\n",
    "}, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate public ClaimChain at one of the points (it's slower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = breakpoints[4]\n",
    "private_report = private_reports[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute new reports\n",
    "#with dynamic_public_setting.as_default():\n",
    "#    context = Context(enron_log[offset:offset+LOG_CHUNK_SIZE], social_graph=social_graph)\n",
    "#    public_report = simulate_claimchain(context)\n",
    "#with open('reports/public_claimchain_report-%d.pkl' % offset, 'wb') as h:\n",
    "#    pickle.dump(public_report, h)\n",
    "\n",
    "# Load computed reports\n",
    "with open('reports/public_claimchain_report-%d.pkl' % offset, 'rb') as h:\n",
    "    public_report = pickle.load(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare public and private versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "fig.set_tight_layout(tight=True)\n",
    "\n",
    "visualize_encryption_status_history('Public claims',\n",
    "                                    public_report.encryption_status_data,\n",
    "                                    public_report.link_status_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    show_title=True,\n",
    "                                    ax=axes[0])\n",
    "\n",
    "visualize_encryption_status_history('Private claims',\n",
    "                                    private_report.encryption_status_data,\n",
    "                                    private_report.link_status_data,\n",
    "                                    batch_size=batch_size,\n",
    "                                    show_legend=True,\n",
    "                                    show_title=True,\n",
    "                                    ax=axes[1])\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "for tick in [20, 40, 60, 80]:\n",
    "    axes[0].axhline(tick, 0, 10000, alpha=.25, linestyle='-')\n",
    "    axes[1].axhline(tick, 0, 10000, alpha=.25, linestyle='-')\n",
    "    \n",
    "for tick in [2000, 4000, 6000, 8000]:\n",
    "    axes[0].axvline(tick, 0, 100, alpha=.25, linestyle='-')\n",
    "    axes[1].axvline(tick, 0, 100, alpha=.25, linestyle='-')\n",
    "\n",
    "fig.savefig('images/enc_status_data_global.pdf')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "fig.set_tight_layout(tight=True)\n",
    "\n",
    "visualize_encryption_status_history('Public claims',\n",
    "                                    public_report.encryption_status_data,\n",
    "                                    public_report.link_status_data,\n",
    "                                    public_report.participants_type_data == ParticipantsTypes.userset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    show_title=True,\n",
    "                                    ax=axes[0])\n",
    "\n",
    "visualize_encryption_status_history('Private claims',\n",
    "                                    private_report.encryption_status_data,\n",
    "                                    private_report.link_status_data,\n",
    "                                    private_report.participants_type_data == ParticipantsTypes.userset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    show_title=True,\n",
    "                                    ax=axes[1])\n",
    "\n",
    "fig.set_figwidth(10)\n",
    "\n",
    "for tick in [20, 40, 60, 80]:\n",
    "    axes[0].axhline(tick, 0, 10000, alpha=.25)\n",
    "    axes[1].axhline(tick, 0, 10000, alpha=.25)\n",
    "    \n",
    "for tick in [2000, 4000, 6000, 8000]:\n",
    "    axes[0].axvline(tick, 0, 100, alpha=.25, linestyle='-')\n",
    "    axes[1].axvline(tick, 0, 100, alpha=.25, linestyle='-')\n",
    "    \n",
    "fig.savefig('images/enc_status_data_userset.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Public ClaimChain')\n",
    "a = get_average_enc_status_data(public_report)\n",
    "b = get_average_enc_status_data(public_report,\n",
    "    mask=private_report.participants_type_data==ParticipantsTypes.userset)\n",
    "display(pd.concat({'global': a, 'userset': b}, axis=1))\n",
    "\n",
    "print('Private ClaimChain')\n",
    "a = get_average_enc_status_data(private_report)\n",
    "b = get_average_enc_status_data(private_report,\n",
    "    mask=private_report.participants_type_data==ParticipantsTypes.userset)\n",
    "display(pd.concat({'global': a, 'userset': b}, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_storage_data(report, batch_size=2500):\n",
    "    \n",
    "    def collect_data_points(series_dict):\n",
    "        data_points_by_batch = defaultdict(list)\n",
    "        for offset in range(0, LOG_CHUNK_SIZE, batch_size):\n",
    "            for series in series_dict.values():\n",
    "                data_slice = series.loc[offset:offset + batch_size] \\\n",
    "                            .dropna().values\n",
    "                if len(data_slice) == 0:\n",
    "                    continue\n",
    "                data_point = data_slice.mean() / 1024\n",
    "                data_points_by_batch[offset + batch_size].append(data_point)\n",
    "\n",
    "        for offset in range(0, LOG_CHUNK_SIZE, batch_size):\n",
    "            points = data_points_by_batch[offset + batch_size]\n",
    "            data_points_by_batch[offset + batch_size] = pd.Series(points)\n",
    "\n",
    "        result = pd.DataFrame(data_points_by_batch)\n",
    "        return result\n",
    "\n",
    "    bandwidth_data = collect_data_points(report.outgoing_bandwidth_data)\n",
    "    gossip_storage_data = collect_data_points(report.gossip_store_size_data)\n",
    "    local_storage_data = collect_data_points(report.local_store_size_data)\n",
    "    \n",
    "    return bandwidth_data, gossip_storage_data, local_storage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = private_reports[4]\n",
    "private_bandwidth_data, private_gossip_storage_data, private_local_storage_data = \\\n",
    "    get_average_storage_data(report)\n",
    "public_bandwidth_data, public_gossip_storage_data, public_local_storage_data = \\\n",
    "    get_average_storage_data(public_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.legend(frameon=True, loc=\"right bottom\")\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 30)\n",
    "private_bandwidth_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/private_bandwidth.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.legend(frameon=True, loc=\"right bottom\")\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 2000)\n",
    "public_bandwidth_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/public_bandwidth.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 2000)\n",
    "private_gossip_storage_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/private_gossip_storage.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 20000)\n",
    "public_gossip_storage_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/public_gossip_storage.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 30)\n",
    "private_local_storage_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/private_local_storage.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_ylabel(\"Kb\")\n",
    "ax.set_xlabel(\"Email sent\")\n",
    "ax.set_ylim(0, 5000)\n",
    "public_local_storage_data.plot.box(ax=ax)\n",
    "\n",
    "fig.savefig('images/public_local_storage.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
